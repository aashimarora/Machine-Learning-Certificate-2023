{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold cross validation\n",
    "\n",
    "\n",
    "In this notebook you will use K-fold cross validation to compare two regression models. The two models are Kernel Ridge Regression and Regression Decision Trees. You don't need to understand how these two models work for now and can just use the provided fit_and_predict functions to get predictions for each of the models. \n",
    "\n",
    "The aim of this notebook is to practice K-fold cross validation. It is split into 5 parts:\n",
    "1. Create a function to split the data into k folds \n",
    "2. Performance Metric - create a function to calculate RMSE\n",
    "3. Create a function to run cross validation on the k-folds\n",
    "4. Run cross validation for k={2, ..., 100}, timing each one \n",
    "5. Answer the questions in a markdown cell \n",
    "\n",
    "**NOTE:** Make sure you restart the kernel and re-run the notebook just before you submit it so your answers are consistant. All the packages you need are already imported into the notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will use a sklearn toy dataset. The input values for this dataset are ten baseline variables measured in diabetes patients and the output is a quantitative measure of disease progression one year later. You can read more about the data [here](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1)\n",
      "        x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
      "0  0.800500  1.065488  1.297088  0.459841 -0.929746 -0.732065 -0.912451   \n",
      "1 -0.039567 -0.938537 -1.082180 -0.553505 -0.177624 -0.402886  1.564414   \n",
      "2  1.793307  1.065488  0.934533 -0.119214 -0.958674 -0.718897 -0.680245   \n",
      "3 -1.872441 -0.938537 -0.243771 -0.770650  0.256292  0.525397 -0.757647   \n",
      "4  0.113172 -0.938537 -0.764944  0.459841  0.082726  0.327890  0.171178   \n",
      "\n",
      "        x_7       x_8       x_9         y  \n",
      "0 -0.054499  0.418531 -0.370989 -0.014719  \n",
      "1 -0.830301 -1.436589 -1.938479 -1.001659  \n",
      "2 -0.054499  0.060156 -0.545154 -0.144580  \n",
      "3  0.721302  0.476983 -0.196823  0.699513  \n",
      "4 -0.054499 -0.672502 -0.980568 -0.222496  \n"
     ]
    }
   ],
   "source": [
    "# Do not edit this cell \n",
    "\n",
    "X_, y_ = load_diabetes(return_X_y=True)\n",
    "\n",
    "# standardise the data to help us fit the data (this will be covered later in the course)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_)\n",
    "X = scaler.transform(X_)[:300, :]\n",
    "\n",
    "scaler_y = preprocessing.StandardScaler().fit(y_.reshape(-1, 1))\n",
    "y = scaler_y.transform(y_.reshape(-1, 1))[:300, :]\n",
    "print(y.shape)\n",
    "\n",
    "# to ensure the data stays in the correct order, we will work with dataframes \n",
    "\n",
    "columns = [f'x_{i}' for i in range(X.shape[1])] + ['y']\n",
    "x_columns = [f'x_{i}' for i in range(X.shape[1])]\n",
    "data = pd.DataFrame(data= np.concatenate([X, y.reshape(-1, 1)], axis=1), columns=columns)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit \n",
    "\n",
    "def fit_and_predict_KRR(train, validate):\n",
    "    \"\"\"fit a Kernel Ridge Regression Model on the training data and predict the y values of the validation X data.\n",
    "    :param train: pandas dataframe containing the training data\n",
    "    :param validate: pandas dataframe containing the validation data \n",
    "    :return: predictions at the validation X points Mx1 numpy array\"\"\"\n",
    "    X_train = train[x_columns].to_numpy()\n",
    "    y_train = train['y'].to_numpy()\n",
    "    X_val = validate[x_columns].to_numpy()\n",
    "        \n",
    "    KRR = KernelRidge(alpha=0.1, kernel='rbf', gamma=0.2,  degree=100)\n",
    "    KRR.fit(X_train, y_train)\n",
    "    return KRR.predict(X_val)\n",
    "    \n",
    "    \n",
    "def fit_and_predict_DT(train, validate):\n",
    "    \"\"\"fit a Regression Decision Tree on the training data and predict the y values of the validation X data.\n",
    "    :param train: pandas dataframe containing the training data\n",
    "    :param validate: pandas dataframe containing the validation data \n",
    "    :return: predictions at the validation X points Mx1 numpy array\"\"\"\n",
    "    \n",
    "    X_train = train[x_columns].to_numpy()\n",
    "    y_train = train['y'].to_numpy()\n",
    "    X_val = validate[x_columns].to_numpy()\n",
    "        \n",
    "    DTree = DecisionTreeRegressor(max_depth=6)\n",
    "    DTree.fit(X_train, y_train)\n",
    "    return DTree.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Creating the folds\n",
    "\n",
    "### TO DO:\n",
    "\n",
    "Complete the gaps to crete a function that split the data into k folds. \n",
    "\n",
    "**MARKS: 2 Marks for correctly creating list of how long each fold should be**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k_folds(data, k):\n",
    "    \"\"\"function that returns a list of k folds of the data\"\"\"\n",
    "    \n",
    "    ############################\n",
    "    # Create list of how long each fold should be. The folds should be as even as possible in number, but some may\n",
    "    # need to have an extra data point if the total number of data points isn't divisible by n\n",
    "    len_folds = [int(sum(x)) for x in np.array_split(np.ones(len(data)), k)]\n",
    "    ############################\n",
    "\n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        data_ss = data.sample(n=len_folds[i], random_state=20)\n",
    "        data = data.drop(data_ss.index)\n",
    "        folds.append(data_ss)\n",
    "\n",
    "    return folds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  Performance Metric\n",
    "\n",
    "### TO DO:\n",
    "Write a function that calculates the root mean squared error between predictions and the true y values. Both inputs should be numpy arrays and the function should return a float. \n",
    "\n",
    "**MARKS: 1 mark for correctly writing function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(prediction, true):\n",
    "    return np.sqrt(np.mean(np.square(prediction-true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Cross Valiation\n",
    "\n",
    "### TO DO:\n",
    "\n",
    "Create a function to run the cross validation on both the models by filling out the gaps in the function below. This function will return the average RMSE for each of the models. \n",
    "\n",
    "**MARKS: 6 Marks, one for each of the code blocks to be completed in the function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(folds):\n",
    "    folds = copy.copy(folds) # this creates a new variable which is a copy of folds\n",
    "\n",
    "    rmses_KRR = []  # list to collect the rmses for each fold for the Kernel Ridge Regression\n",
    "    rmses_DT = []   # list to collect the rmses for each fold for the Decision Tree\n",
    "    for i, fold in enumerate(folds):\n",
    "        \n",
    "        ############################\n",
    "        # Write code to create the training and validation sets as DataFrames\n",
    "        \n",
    "        train = pd.concat(folds[:i]+folds[(i+1):])\n",
    "#         train = pd.concat([folds.pop(i)])\n",
    "        validate = fold\n",
    "        \n",
    "        ############################\n",
    "        \n",
    "        ############################\n",
    "        # Use the fit_and_predict functions to create new columns in the validation set for the predictions \n",
    "        # for each model with headings ['KRR_predictions', 'DT_predictions'].\n",
    "        \n",
    "        validate['KRR_predictions'] = fit_and_predict_KRR(train, fold)\n",
    "        validate['DT_predictions'] = fit_and_predict_DT(train, fold)\n",
    "        \n",
    "        ############################\n",
    "        \n",
    "        ############################\n",
    "        # calculate the rmse for the two models and append to rmses_KRR and rmses_DT\n",
    "        \n",
    "        rmses_KRR.append(rmse(validate['KRR_predictions'].to_numpy(), validate['y'].to_numpy()))\n",
    "        rmses_DT.append(rmse(validate['DT_predictions'].to_numpy(), validate['y'].to_numpy()))\n",
    "        \n",
    "        ############################\n",
    "\n",
    "    RMSE_KRR = np.mean(rmses_KRR) # calculate the average RMSEs for kernel ridge regression\n",
    "    RMSE_DT = np.mean(rmses_DT)# calculate the average RMSEs for the decision tree \n",
    "    return RMSE_KRR, RMSE_DT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: \n",
    "For k = 100 calculate the RMSE for each model and print the solutions \n",
    "\n",
    "**MARKS: 2 Marks, one for each of the RMSEs. RMSE_KRR = 0.08646068038691881 and RMSE_DT = 0.0. Note: I think all answers should be the same but it's possible they may vary slightly depending on the learner's code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7953413904964531 0.7691086835088461\n"
     ]
    }
   ],
   "source": [
    "folds =  k_folds(data, 100)\n",
    "RMSE_KRR, RMSE_DT = cross_validation(copy.copy(folds))\n",
    "print(RMSE_KRR, RMSE_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Cross Validation for Different Values of k\n",
    "\n",
    "### TO DO:\n",
    "\n",
    "for k in {2, ..., 100} divide the data into k folds and then run cross validation. Save the results for each run in two lists (one for each model) and then plot a graph of k on the x-axis and RMSE on the y_axis. \n",
    "\n",
    "Use the time function (example in cell below) to time how long the cross validation takes for each value of k. Make a plot of the time against the value of k. \n",
    "\n",
    "**MARKS: 6 Marks. 2 Marks for the correct iteration. 2 Marks for the correct plot of RMSEs, 2 Marks for correct plot of time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "0.0005736351013183594\n"
     ]
    }
   ],
   "source": [
    "# time function example\n",
    "\n",
    "start = time.time()\n",
    "print('hello')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6e40241995b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mRMSE_KRR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE_DT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mKRRs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRMSE_KRR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8db9d71a8dbb>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(folds)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Write code to create the training and validation sets as DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#         train = pd.concat([folds.pop(i)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvalidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     ) -> None:\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             raise TypeError(\n\u001b[1;32m    408\u001b[0m                 \u001b[0;34m\"first argument must be an iterable of pandas \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_instancecheck\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# https://github.com/python/mypy/issues/1006\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# error: 'classmethod' used with a non-method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K=100\n",
    "KRRs = []\n",
    "DTs = []\n",
    "times = []\n",
    "for k in range(2, K):\n",
    "    start = time.time()\n",
    "    folds = k_folds(data, k)\n",
    "    RMSE_KRR, RMSE_DT = cross_validation(folds)\n",
    "    end = time.time()\n",
    "    KRRs.append(RMSE_KRR)\n",
    "    DTs.append(RMSE_DT)\n",
    "    times.append(end - start)\n",
    "    \n",
    "    \n",
    "plt.plot(list(range(2,K)), KRRs, label='KRR')\n",
    "plt.plot(list(range(2,K)), DTs, label='DT')\n",
    "plt.legend()\n",
    "plt.title('RMSEs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('k')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(list(range(2,K)), times)\n",
    "plt.title('time to compute')\n",
    "plt.ylabel('time (s)')\n",
    "plt.xlabel('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9298036669683769, 0.902648483368005, 0.8652785942241344, 0.880885028586549, 0.8899224962701903, 0.8869068524213862, 0.8758217838151858, 0.8598491907287679, 0.8830630945129861, 0.8750251574652751] [0.9787478515561953, 0.9916146510792903, 0.9140320599536105, 0.8683230577899537, 0.972782871555304, 0.9154003128920563, 0.8580610886435834, 0.9059931739819326, 0.8958854699985583, 0.888670483741923]\n"
     ]
    }
   ],
   "source": [
    "print(KRRs[:10], DTs[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 : Questions\n",
    "\n",
    "### TO DO:\n",
    "Answer the following questions in a markdown cell\n",
    "\n",
    "1. Which model would you select based on your cross validation results? Why? \n",
    "2. Looking at the two plots you made, what are the benefits and drawbacks of increasing k? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER:\n",
    "\n",
    "1. The students should select the Decision Tree Regression model as the RMSE is lower \n",
    "2. As k increases, we get more consistant results which is good for reproducibility. However, this is at the cost of computational time. \n",
    "\n",
    "**MARKS: 3 Marks, 1 mark for fist question, 2 marks for recognising that results get more consistant but comp time increases as k increases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

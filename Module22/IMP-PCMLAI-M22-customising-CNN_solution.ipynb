{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 solution:\n",
    "1: Fashion MNIST is a built in dataset for torchvision and can be loaded with another method of torchvision.datasets. As the images are black and white rather than rgb valued the transformation required also needs to be updated to accept a single input value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "    \n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train = True,\n",
    "                                        download=True, transform= transform)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data',  train= False,\n",
    "                                        download=True, transform = transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=20,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,  batch_size = 20, \n",
    "                                shuffle = True, num_workers = 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - 6 Solution\n",
    "\n",
    "2: The input is now a black and white intensity rater than rgb value, therefore the inputs dimensionality needs to be one rather than 2. This is done with the first argument of the self.conv1 attribute\n",
    "\n",
    "3: The 3rd argument from the self.conv1 controls the kernel size \n",
    "\n",
    "4: The self.pool attribute needs to be updated, as the kernel is no longer square a tuple (3,2) needs to be used instead of an integer for the kernel size\n",
    "\n",
    "5: The first fully connected layer needs to accept the flattened set of images, which in this case requires 12*16 = 192 inputs  \n",
    "\n",
    "6: The flattening step needs to be updated to the correct size (192) for the new images with new convolutions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptedLeNet: total params: 38450\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super(Net, self).__init__()\n",
    "        if name:\n",
    "            self.name = name\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool = nn.MaxPool2d((3,2), 2)\n",
    "        self.conv2 = nn.Conv2d(10, 16, 5)\n",
    "        self.fc1 = nn.Linear(192, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        # compute the total number of parameters\n",
    "        total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(self.name + ': total params:', total_params)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 192)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(name='AdaptedLeNet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.169\n",
      "[2,  2000] loss: 0.558\n",
      "[3,  2000] loss: 0.469\n",
      "[4,  2000] loss: 0.421\n",
      "[5,  2000] loss: 0.377\n",
      "[6,  2000] loss: 0.353\n",
      "[7,  2000] loss: 0.335\n",
      "[8,  2000] loss: 0.321\n",
      "[9,  2000] loss: 0.306\n",
      "[10,  2000] loss: 0.297\n",
      "[11,  2000] loss: 0.286\n",
      "[12,  2000] loss: 0.278\n",
      "[13,  2000] loss: 0.267\n",
      "[14,  2000] loss: 0.262\n",
      "[15,  2000] loss: 0.256\n",
      "[16,  2000] loss: 0.250\n",
      "[17,  2000] loss: 0.244\n",
      "[18,  2000] loss: 0.239\n",
      "[19,  2000] loss: 0.236\n",
      "[20,  2000] loss: 0.229\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy of T-shirt/top : 81 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 86 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 94 %\n",
      "Accuracy of Shirt : 66 %\n",
      "Accuracy of Sneaker : 89 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classes = torchvision.datasets.FashionMNIST.classes\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb0921dd7555f165ba26ea86a95e1df93ce9c4113cf6dfb5e7b2f702ebc2fb7f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

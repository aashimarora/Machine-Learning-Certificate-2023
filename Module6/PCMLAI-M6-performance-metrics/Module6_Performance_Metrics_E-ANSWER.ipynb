{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pathlib as pl\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Model Selection\n",
    "\n",
    "In this notebook you will fit polynomials to data to decide which order of polynomial is the best fit. Unlike before, the data you will be using is 3 dimensional, meaning it isn't possible to plot. Instead, you will write functions to calculate various metrics that are used to determine model fit. \n",
    "\n",
    "Complete this notebook, then answer the questions that go along side it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "seed = 2022\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = pl.Path(os.getcwd()) / f'M6_Performance_Metrics_Data.csv'\n",
    "with open(path_csv, 'rb') as file:\n",
    "    data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        x1        x2        x3          y\n",
      "0           0  0.382303 -1.596593  1.233776   4.935364\n",
      "1           1  1.902436  1.579109 -0.341741  25.138660\n",
      "2           2 -1.689244  1.298489 -1.472081  -4.786340\n",
      "3           3 -1.510509  1.937616 -1.600244  -3.185759\n",
      "4           4  1.621717  0.515558 -1.869644  19.712731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.head())\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Split the data into training, validation and test sets\n",
    "\n",
    "### TO DO: write a function that splits the data into traning, validation and test sets.\n",
    "\n",
    "The function should take as inputs the dataframe and the percentage splits for each of training, validation and test. It should output 3 dataframes, one for each of the sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your function here ##\n",
    "from collections import namedtuple\n",
    "Split = namedtuple('Split', ['training', 'validation', 'test'])\n",
    "seed = 2022\n",
    "np.random.seed(seed)\n",
    "def split(dataframe, splits=Split(training=0.4,validation=0.3,test=0.3)):\n",
    "    rows = dataframe.shape[0]\n",
    "    \n",
    "    n_train = int(rows*splits.training)\n",
    "    n_validate = int(rows*splits.validation)\n",
    "    \n",
    "    # generate a random permutation of indices of the data and split into training, validation and test\n",
    "    perm = np.random.permutation(rows)\n",
    "    indices_train, indices_validate, indices_test = np.split(perm, [n_train, n_train+ n_validate])\n",
    "    print('Train:', indices_train, 'Validate', indices_validate)\n",
    "    return dataframe.iloc[indices_train], dataframe.iloc[indices_validate], dataframe.iloc[indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, data_split):\n",
    "    \"\"\"function to divide a dataframe into training, validation and test dataframes\n",
    "    :param df: the full dataframe which is to be divided \n",
    "    :param data_split: a list containing the fraction of the full dataframe for each\n",
    "    of training, validation and test, in that order\n",
    "    :return training, validation, test: dataframes for each of the sets\"\"\"\n",
    "    \n",
    "    training = df.sample(frac=data_split[0])\n",
    "    validation = df.drop(training.index).sample(frac=data_split[1]*len(df)/len(df.drop(training.index)))\n",
    "    test = df.drop(validation.index).drop(training.index)\n",
    "    \n",
    "    return training, validation, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: Use your function to split the data so the training set has 40% of the data and the validation and test sets have 30% of the data each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [79 76 83  5 35 57 22 96 67 58 93  3 69 60 39 17 54 44 61 94 32 84 70 20\n",
      " 50 81 47 51  4 97 30 10  1 25 65  7 26 31 82  6] Validate [ 9 28 62 63 89 34 95 66  8 40 90 59 36  0 68 77 46 43 78 73 21 74 85 29\n",
      " 71 64 91 42 52 13]\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = split(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0        x1        x2        x3          y\n",
      "79          79 -1.386593  1.158374  1.994851  12.563918\n",
      "76          76  1.790229  0.389979  1.157690   9.563458\n",
      "83          83 -1.893098  0.440954 -0.797749  -2.209804\n",
      "5            5 -1.928868 -1.475115 -0.677217  24.007974\n",
      "35          35  0.497772  0.803435 -0.801939   3.127374\n",
      "57          57  0.403963 -1.396032  0.560340   2.279149\n",
      "22          22 -0.359099  0.952081  1.743385  12.820280\n",
      "96          96 -1.236030  1.027829  0.105539  -0.461212\n",
      "67          67  1.384385 -0.544277  1.379405   4.000594\n",
      "58          58 -1.268421 -1.431103  0.282959   8.868657\n",
      "93          93  1.636172  0.576516 -1.850643  20.271508\n",
      "3            3 -1.510509  1.937616 -1.600244  -3.185759\n",
      "69          69 -1.591721  1.030819  1.479829  -0.869927\n",
      "60          60  0.948066  1.626476 -0.151725   5.842609\n",
      "39          39  1.552398 -1.767069 -0.447956 -10.507609\n",
      "17          17 -0.880164  0.077271 -1.176139   5.167053\n",
      "54          54  0.583874 -1.257991 -1.220823   4.843647\n",
      "44          44  0.577581  0.561392  0.003785   3.165806\n",
      "61          61  1.190430 -0.458804  0.809956   1.873865\n",
      "94          94  0.632650 -1.628347  1.683086  10.451087\n",
      "32          32  0.865403  0.688480 -0.879786   4.057074\n",
      "84          84 -0.161022  0.033720  0.130973   3.242069\n",
      "70          70 -0.202824  1.552231  0.057511   3.076659\n",
      "20          20  1.148637 -0.128755 -0.384135   2.508796\n",
      "50          50  0.457478 -1.022804  0.046429   3.123830\n",
      "81          81 -1.860359  1.456796 -0.716871 -15.107263\n",
      "47          47 -1.892543  0.086870  1.675673   9.825095\n",
      "51          51 -1.598495 -0.562274 -0.477370   7.689515\n",
      "4            4  1.621717  0.515558 -1.869644  19.712731\n",
      "97          97 -0.415708 -0.626697  1.076959   4.514128\n",
      "30          30 -0.251202  1.921266  0.645585   3.722602\n",
      "10          10  1.009490 -0.526579 -1.682165   9.920730\n",
      "1            1  1.902436  1.579109 -0.341741  25.138660\n",
      "25          25  1.051658  1.366586 -0.973434   6.863962\n",
      "65          65  0.308612 -0.923909 -0.235798   3.187302\n",
      "7            7  1.409334 -1.663275 -0.899389  -5.856637\n",
      "26          26 -0.876544 -1.219281 -0.748145   4.675373\n",
      "31          31  0.445146 -0.360236  0.929659   3.703327\n",
      "82          82  1.157484 -0.758447  1.424520   4.652022\n",
      "6            6 -0.581466 -1.672979 -0.331812   3.786323     Unnamed: 0        x1        x2        x3          y\n",
      "29          29 -1.562076 -0.827114 -1.350314  12.511955\n",
      "33          33  1.842447 -0.730029 -1.208410  -3.896164\n",
      "63          63  1.234521  0.049401  1.836281  14.890609\n",
      "73          73  1.090002  1.293430  1.852566  17.887657\n",
      "49          49  1.800842  0.017108 -0.129432   3.380950\n",
      "11          11 -1.791881  1.247531 -1.404802  -7.885392\n",
      "23          23 -0.496090  1.552690 -1.333864   5.704070\n",
      "87          87 -0.206884  0.556944 -0.991252   4.303754\n",
      "38          38 -1.540892 -1.914233  0.094931  16.939395\n",
      "15          15 -0.585360 -0.023728  1.032742   4.072249\n",
      "27          27 -0.699577  0.431419 -0.420143   3.276903\n",
      "62          62 -1.670056  0.362760  1.394161   3.089655\n",
      "98          98 -0.467675  1.527521  0.675122   2.895005\n",
      "0            0  0.382303 -1.596593  1.233776   4.935364\n",
      "92          92 -0.170697  1.568891 -1.732563  11.339542\n",
      "18          18 -0.430916  1.401128 -0.480641   2.783550\n",
      "45          45 -0.355683 -0.487864  1.451096   7.685456\n",
      "48          48  1.252673 -1.396606 -1.472395   2.493270\n",
      "71          71 -0.162152  1.373440  0.411232   3.160265\n",
      "68          68  1.378123  1.912483  0.119204  13.292659\n",
      "99          99 -0.126524  1.807901 -0.740513   3.114022\n",
      "12          12 -1.096106  0.560155 -0.072257   2.073382\n",
      "80          80 -1.359348 -1.780858  0.847985  12.234655\n",
      "16          16 -1.144002  0.949800  0.866272   1.223742\n",
      "53          53 -1.865304 -0.964960 -1.988133  30.539239\n",
      "52          52  1.262583  0.234466 -0.132652   4.148850\n",
      "64          64  0.897903  1.426707  0.797498   5.384437\n",
      "41          41  1.026876  0.085351 -0.194542   2.850317\n",
      "85          85  0.406381 -0.546997  1.114878   4.507444\n",
      "86          86 -0.701848  0.202234 -1.035928   4.027855     Unnamed: 0        x1        x2        x3          y\n",
      "2            2 -1.689244  1.298489 -1.472081  -4.786340\n",
      "8            8 -1.068701 -0.764019  0.805561   5.126408\n",
      "9            9 -0.473046 -0.477313 -0.483007   3.306021\n",
      "13          13  1.629689  1.228442 -1.951963  27.977851\n",
      "14          14  1.889985  0.464764 -1.297304  12.089570\n",
      "19          19  1.069111 -1.184526  0.576039   0.049595\n",
      "21          21 -0.281362 -1.523042 -0.685317   3.111517\n",
      "24          24  1.808328 -0.137865 -0.016387   1.468578\n",
      "28          28 -1.044932 -1.981752  1.856430  20.028148\n",
      "34          34 -1.947620  0.509861  0.771109  -4.522426\n",
      "36          36  0.723287 -0.578830 -0.655962   3.565216\n",
      "37          37 -1.066721 -0.806202 -1.603302  11.504107\n",
      "40          40 -1.057484 -0.005690 -0.318702   2.645363\n",
      "42          42 -0.669088 -1.536327 -0.522579   4.468465\n",
      "43          43 -1.091948 -0.585556  0.894491   4.815922\n",
      "46          46 -0.374509  0.734371 -1.992420  18.659099\n",
      "55          55 -1.277623 -0.817546 -1.888549  19.193692\n",
      "56          56  1.127148  0.655574  0.900366   5.513091\n",
      "59          59 -1.942558 -1.115170  1.361757  22.344950\n",
      "66          66  0.032865  0.273388  1.605923   9.592436\n",
      "72          72  0.205552 -0.087599  0.738497   3.580353\n",
      "74          74 -0.409170 -1.331770  0.803696   3.611360\n",
      "75          75  0.627830 -1.468808 -1.339753   5.722045\n",
      "77          77 -1.207163  1.244802  1.636311   5.839282\n",
      "78          78 -1.987114  0.326288 -0.327055  -2.436745\n",
      "88          88 -1.890215 -0.276761 -1.039610   7.361286\n",
      "89          89 -1.083336  0.410126 -1.567022   8.244415\n",
      "90          90  1.210553 -1.960263  1.896941   9.292994\n",
      "91          91  1.680248 -1.899313  0.861771 -14.653928\n",
      "95          95 -0.369062  1.344716 -0.545936   2.848421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### write your code here ####\n",
    "#train, validation, test = split(data)\n",
    "train, validation, test = split_dataframe(data, [0.4,0.3,0.3])\n",
    "print(train,validation,test)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Write Metrics Functions \n",
    "\n",
    "### TO DO: Write the functions that calcluate the metrics you will use to evaluate the model fits\n",
    "\n",
    "Write Functions that return:\n",
    "- The mean absolute error\n",
    "- The average error\n",
    "- The mean absolute percentage error \n",
    "- The root mean squared error \n",
    "- The total sum of squared errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here ##\n",
    "def round_error(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        return round(result, 3)\n",
    "    return wrapper\n",
    "\n",
    "@round_error\n",
    "def mean_absolute_error(Y_actual, Y_pred):\n",
    "    return np.mean(np.abs(Y_actual - Y_pred))\n",
    "\n",
    "@round_error\n",
    "def average_error(Y_actual, Y_pred):\n",
    "    return np.mean(Y_pred - Y_actual)\n",
    "\n",
    "@round_error\n",
    "def mean_absolute_perc_error(Y_actual, Y_pred):\n",
    "    return 100 * np.mean(np.abs((Y_pred - Y_actual)/Y_actual))\n",
    "\n",
    "@round_error\n",
    "def RMSE(Y_actual, Y_pred):\n",
    "    return np.sqrt(np.mean((Y_actual - Y_pred)**2))\n",
    "    \n",
    "@round_error\n",
    "def total_sum_squared_error(Y_actual, Y_pred):\n",
    "    return np.sum((Y_actual - Y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Fit models to training data and calculate performance metric on validation sets\n",
    "\n",
    "For polynomials of order 1, 2, 3, and 4, you will use fit_model to fit each each model. This function uses scikit-learn polynomial regression. \n",
    "\n",
    "\n",
    "### TODO: write function to convert dataframe into numpy arrays\n",
    "\n",
    "The scikit-learn functions take numpy arrays as their inputs. Therefore before you can fit any data you need to write a function to turn a dataframe with columns [x1, x2, x3, y] into two numpy arrays: X and y. X should have dimensions (N, D), where N is the number of data points and D is the dimensionality of the data (in this case 3). y should have dimensions (N, ). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X, y, order):\n",
    "    \"\"\"creates scikit-learn regression object and fits it to the X and y data\"\"\"\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=order)),\n",
    "                      ('linear', LinearRegression(fit_intercept=False))])\n",
    "    model = model.fit(X, y)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your function here ## \n",
    "def convert(df):\n",
    "    return np.array(df[['x1', 'x2', 'x3']]), np.array(df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: For polynomials of order 1 to 6 inclusive: \n",
    "1. Fit a polynomial to the training data using the fit_model function \n",
    "2. Use model.predict(X) to get the model predictions on the validation set\n",
    "3. Store the model in a dictionary of models where the keys indicate the order and the items are the models\n",
    "4. Store the predictions in a seperate dictionary where the keys indicate the order and the items are numpy arrays of the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here ##\n",
    "models = {}\n",
    "predictions = {}\n",
    "X_train, Y_train = convert(train)\n",
    "X_val, Y_val = convert(validation)\n",
    "for order in range(1,7):\n",
    "    model = fit_model(X_train,Y_train,order)\n",
    "    models[order] = model\n",
    "    predictions[order] = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Calculate metrics for each of the models\n",
    "\n",
    "Now we want to calculate the metrics for each of the models. \n",
    "\n",
    "\n",
    "### TODO: Use the dictionary of predictions you have to caluclate and record (could be in a dataframe, or you could plot it on a graph) each of the metrics. \n",
    "1. Calculate each of the metrics for the model using the functions you wrote before\n",
    "2. Store the metrics in a dataframe, with one row for each model or plot on a graph\n",
    "3. Answer the questions that go alongside this notebook \n",
    "\n",
    "HINT: you can write a list of functions of the form:\n",
    "\n",
    "methods = [RMSE, average_error, mean_abs_percent_error, total_sum_squared_error]\n",
    "\n",
    "which you can then iterate over using a for loop. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MAE     AE    MAPE   RMSE      TSSE\n",
      "0  5.101 -1.204  77.700  7.684  1771.097\n",
      "1  2.625  0.389  56.927  3.282   323.116\n",
      "2  4.805  0.766  86.271  6.404  1230.391\n",
      "3  1.050 -0.328  15.689  1.780    95.022\n",
      "4  1.799 -0.124  25.506  2.956   262.134\n",
      "5  3.386  1.603  33.060  8.298  2065.943\n"
     ]
    }
   ],
   "source": [
    "## write your code here ##\n",
    "str_map = {}\n",
    "str_map['MAE'] = mean_absolute_error\n",
    "str_map['AE'] = average_error\n",
    "str_map['MAPE'] = mean_absolute_perc_error\n",
    "str_map['RMSE'] = RMSE\n",
    "str_map['TSSE'] = total_sum_squared_error\n",
    "\n",
    "columns = str_map.keys()\n",
    "errors = []\n",
    "for key in predictions:\n",
    "    error = []\n",
    "    for func in str_map:    \n",
    "        error.append(str_map[func](Y_val, predictions[key]))\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame(errors, columns=columns)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Use the test set to evaluate the performance of your chosen model\n",
    "\n",
    "### TODO: For your selected model, calculate the RMSE, Average Error and Mean Absolute Percentage Error of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.447\n",
      "Average Error: 0.039\n",
      "Mean Absolute percentage Error: 39.253\n"
     ]
    }
   ],
   "source": [
    "## write your code here ## \n",
    "X_test, Y_test = convert(test)\n",
    "best = 4\n",
    "Y_pred = models[best].predict(X_test)\n",
    "print('RMSE:', RMSE(Y_test, Y_pred))\n",
    "print('Average Error:', average_error(Y_test, Y_pred))\n",
    "print('Mean Absolute percentage Error:', mean_absolute_perc_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1.375\n",
      "AE 0.039\n",
      "MAPE 39.253\n",
      "RMSE 2.447\n",
      "TSSE 179.691\n"
     ]
    }
   ],
   "source": [
    "for func in str_map:    \n",
    "    print(func, str_map[func](Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

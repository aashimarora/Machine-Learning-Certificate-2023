{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pathlib as pl\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Model Selection\n",
    "\n",
    "In this notebook you will fit polynomials to data to decide which order of polynomial is the best fit. Unlike before, the data you will be using is 3 dimensional, meaning it isn't possible to plot. Instead, you will write functions to calculate various metrics that are used to determine model fit. \n",
    "\n",
    "Complete this notebook, then answer the questions that go along side it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "seed = 2022\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = pl.Path(os.getcwd()) / f'M6_Performance_Metrics_Data.csv'\n",
    "with open(path_csv, 'rb') as file:\n",
    "    data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        x1        x2        x3          y\n",
      "0           0  0.382303 -1.596593  1.233776   4.935364\n",
      "1           1  1.902436  1.579109 -0.341741  25.138660\n",
      "2           2 -1.689244  1.298489 -1.472081  -4.786340\n",
      "3           3 -1.510509  1.937616 -1.600244  -3.185759\n",
      "4           4  1.621717  0.515558 -1.869644  19.712731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.head())\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Split the data into training, validation and test sets\n",
    "\n",
    "### TO DO: write a function that splits the data into traning, validation and test sets.\n",
    "\n",
    "The function should take as inputs the dataframe and the percentage splits for each of training, validation and test. It should output 3 dataframes, one for each of the sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your function here ##\n",
    "from collections import namedtuple\n",
    "Split = namedtuple('Split', ['training', 'validation', 'test'])\n",
    "\n",
    "def split(dataframe, splits=Split(training=0.4,validation=0.3,test=0.3)):\n",
    "    rows = dataframe.shape[0]\n",
    "    \n",
    "    n_train = int(rows*splits.training)\n",
    "    n_validate = int(rows*splits.validation)\n",
    "    \n",
    "    # generate a random permutation of indices of the data and split into training, validation and test\n",
    "    perm = np.random.permutation(rows)\n",
    "    indices_train, indices_validate, indices_test = np.split(perm, [n_train, n_train+ n_validate])\n",
    "    \n",
    "    return dataframe.iloc[indices_train], dataframe.iloc[indices_validate], dataframe.iloc[indices_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: Use your function to split the data so the training set has 40% of the data and the validation and test sets have 30% of the data each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### write your code here ####\n",
    "train, validation, test = split(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Write Metrics Functions \n",
    "\n",
    "### TO DO: Write the functions that calcluate the metrics you will use to evaluate the model fits\n",
    "\n",
    "Write Functions that return:\n",
    "- The mean absolute error\n",
    "- The average error\n",
    "- The mean absolute percentage error \n",
    "- The root mean squared error \n",
    "- The total sum of squared errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here ##\n",
    "def round_error(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        return round(result, 3)\n",
    "    return wrapper\n",
    "\n",
    "@round_error\n",
    "def mean_absolute_error(Y_actual, Y_pred):\n",
    "    return np.mean(np.abs(Y_actual - Y_pred))\n",
    "\n",
    "@round_error\n",
    "def average_error(Y_actual, Y_pred):\n",
    "    return np.mean(Y_pred - Y_actual)\n",
    "\n",
    "@round_error\n",
    "def mean_absolute_perc_error(Y_actual, Y_pred):\n",
    "    return 100 * np.mean(np.abs((Y_pred - Y_actual)/Y_actual))\n",
    "\n",
    "@round_error\n",
    "def RMSE(Y_actual, Y_pred):\n",
    "    return np.sqrt(np.mean((Y_actual - Y_pred)**2))\n",
    "    \n",
    "@round_error\n",
    "def total_sum_squared_error(Y_actual, Y_pred):\n",
    "    return np.sum((Y_actual - Y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Fit models to training data and calculate performance metric on validation sets\n",
    "\n",
    "For polynomials of order 1, 2, 3, and 4, you will use fit_model to fit each each model. This function uses scikit-learn polynomial regression. \n",
    "\n",
    "\n",
    "### TODO: write function to convert dataframe into numpy arrays\n",
    "\n",
    "The scikit-learn functions take numpy arrays as their inputs. Therefore before you can fit any data you need to write a function to turn a dataframe with columns [x1, x2, x3, y] into two numpy arrays: X and y. X should have dimensions (N, D), where N is the number of data points and D is the dimensionality of the data (in this case 3). y should have dimensions (N, ). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X, y, order):\n",
    "    \"\"\"creates scikit-learn regression object and fits it to the X and y data\"\"\"\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=order)),\n",
    "                      ('linear', LinearRegression(fit_intercept=False))])\n",
    "    model = model.fit(X, y)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your function here ## \n",
    "def convert(df):\n",
    "    return np.array(df[['x1', 'x2', 'x3']]), np.array(df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: For polynomials of order 1 to 6 inclusive: \n",
    "1. Fit a polynomial to the training data using the fit_model function \n",
    "2. Use model.predict(X) to get the model predictions on the validation set\n",
    "3. Store the model in a dictionary of models where the keys indicate the order and the items are the models\n",
    "4. Store the predictions in a seperate dictionary where the keys indicate the order and the items are numpy arrays of the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here ##\n",
    "models = {}\n",
    "predictions = {}\n",
    "X_train, Y_train = convert(train)\n",
    "X_val, Y_val = convert(validation)\n",
    "for order in range(1,7):\n",
    "    model = fit_model(X_train,Y_train,order)\n",
    "    models[order] = model\n",
    "    predictions[order] = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Calculate metrics for each of the models\n",
    "\n",
    "Now we want to calculate the metrics for each of the models. \n",
    "\n",
    "\n",
    "### TODO: Use the dictionary of predictions you have to caluclate and record (could be in a dataframe, or you could plot it on a graph) each of the metrics. \n",
    "1. Calculate each of the metrics for the model using the functions you wrote before\n",
    "2. Store the metrics in a dataframe, with one row for each model or plot on a graph\n",
    "3. Answer the questions that go alongside this notebook \n",
    "\n",
    "HINT: you can write a list of functions of the form:\n",
    "\n",
    "methods = [RMSE, average_error, mean_abs_percent_error, total_sum_squared_error]\n",
    "\n",
    "which you can then iterate over using a for loop. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MAE     AE    MAPE   RMSE      TSSE\n",
      "0  5.733 -2.219  60.411  8.555  2195.562\n",
      "1  2.865  0.954  45.649  3.466   360.422\n",
      "2  3.948  0.145  53.732  5.003   750.832\n",
      "3  1.118  0.333  11.314  2.202   145.399\n",
      "4  2.088 -0.693  20.220  3.482   363.805\n",
      "5  2.797  1.546  26.243  4.616   639.222\n"
     ]
    }
   ],
   "source": [
    "## write your code here ##\n",
    "str_map = {}\n",
    "str_map['MAE'] = mean_absolute_error\n",
    "str_map['AE'] = average_error\n",
    "str_map['MAPE'] = mean_absolute_perc_error\n",
    "str_map['RMSE'] = RMSE\n",
    "str_map['TSSE'] = total_sum_squared_error\n",
    "\n",
    "columns = str_map.keys()\n",
    "errors = []\n",
    "for key in predictions:\n",
    "    error = []\n",
    "    for func in str_map:    \n",
    "        error.append(str_map[func](Y_val, predictions[key]))\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame(errors, columns=columns)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Use the test set to evaluate the performance of your chosen model\n",
    "\n",
    "### TODO: For your selected model, calculate the RMSE, Average Error and Mean Absolute Percentage Error of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.076\n",
      "Average Error: -0.622\n",
      "Mean Absolute percentage Error: 43.629\n"
     ]
    }
   ],
   "source": [
    "## write your code here ## \n",
    "X_test, Y_test = convert(test)\n",
    "best = 4\n",
    "Y_pred = models[best].predict(X_test)\n",
    "print('RMSE:', RMSE(Y_test, Y_pred))\n",
    "print('Average Error:', average_error(Y_test, Y_pred))\n",
    "print('Mean Absolute percentage Error:', mean_absolute_perc_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1.308\n",
      "AE -0.622\n",
      "MAPE 43.629\n",
      "RMSE 2.076\n",
      "TSSE 129.313\n"
     ]
    }
   ],
   "source": [
    "for func in str_map:    \n",
    "    print(func, str_map[func](Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
